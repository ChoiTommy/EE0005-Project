{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset cleaning\n",
    "---\n",
    "EE0005 Mini-project EE10\n",
    "\n",
    "Group **Veriton**\n",
    "\n",
    "Members: Hoi To, Joel Lee, Monicka, Yashwanth\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData = pd.read_csv('Datasets/fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast `fraudulent` to `bool` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData['fraudulent'] = jobData['fraudulent'].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting `salary_range`\n",
    "\n",
    "The cleaned salary range are stored in column `salary_lower_limit` and `salary_upper_limit`\n",
    "\n",
    "For data like \"40000-59000\", the corresponding lower and upper limits are 40000 and 59000\n",
    "\n",
    "For data with NaN, they are all stored as (0, 0)\n",
    "\n",
    "For data with just one value like \"40000\", lower limit is stored as 0 and upper as 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData['salary_range'] = jobData['salary_range'].fillna('0')\n",
    "jobData['salary_range'] = jobData['salary_range'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_range(t):\n",
    "    split_data = t.split('-')\n",
    "    \n",
    "    #For cases with no hyphen, meaning theres only 1 value in the column\n",
    "    if (len(split_data) != 2):\n",
    "        \n",
    "        #If the value is a number, then that number is the upper end, lower end is 0\n",
    "        if (split_data[0].isnumeric()):\n",
    "            return (0, int(split_data[0]))\n",
    "        \n",
    "        #If there is only 1 value and it is not a number, it is an invalid input\n",
    "        return (0, 0)\n",
    "    \n",
    "    #If there is a hyphen and both ends are numbers, those numbers give the range\n",
    "    if (split_data[0].isnumeric() and split_data[1].isnumeric()):\n",
    "        return (int(split_data[0]), int(split_data[1]))\n",
    "    \n",
    "    #If there is a hyphen but one of the range is not a number. e.g. \"4-Apr\"\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = []\n",
    "upper = []\n",
    "for i in range(len(jobData)):\n",
    "    l, u = extract_salary_range(jobData['salary_range'][i])\n",
    "    lower.append(l)\n",
    "    upper.append(u)\n",
    "\n",
    "jobData[\"salary_lower_limit\"] = lower\n",
    "jobData[\"salary_upper_limit\"] = upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning `function`, `required_experience`, `employment_type`, `required_education` and `industry` using One-Hot encoding\n",
    "\n",
    "Columns can be accessed by using `<category>_type_is_<name>`.\n",
    "\n",
    "For example, if you want to know whether the job has the function of 'Marketing', simply use `jobPostings[\"function_type_is_Marketing\"]` to generate a column of bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData[\"function\"].fillna(value='Not specified', inplace=True)\n",
    "jobData['employment_type'].fillna(value='Not specified', inplace=True)\n",
    "jobData['required_experience'].fillna(value='Not specified', inplace=True)\n",
    "jobData['required_education'].fillna(value='Unspecified', inplace=True)\n",
    "jobData['industry'].fillna(value='Not specified', inplace=True)\n",
    "\n",
    "\n",
    "jobData = jobData.astype({\n",
    "    'function': 'category',\n",
    "    'employment_type': 'category',\n",
    "    'required_experience': 'category',\n",
    "    'required_education': 'category',\n",
    "    'industry': 'category',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"function\"]\n",
    "\n",
    "jobData = pd.get_dummies(jobData, columns=[\"function\"], prefix=[\"function_type_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"required_experience\"]\n",
    "\n",
    "jobData = pd.get_dummies(jobData, columns=[\"required_experience\"], prefix=[\"required_experience_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"employment_type\"]\n",
    "\n",
    "jobData = pd.get_dummies(jobData, columns=[\"employment_type\"], prefix=[\"employment_type_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"required_education\"]\n",
    "\n",
    "jobData = pd.get_dummies(jobData, columns=[\"required_education\"], prefix=[\"required_education_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"industry\"]\n",
    "\n",
    "jobData = pd.get_dummies(jobData, columns=[\"industry\"], prefix=[\"industry_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract country codes from `location` to column `country_code`\n",
    "\n",
    "'NS' refers to not being specified, rather than a actual country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData[\"location\"] = jobData[\"location\"].fillna(\"NS\") # Not specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_country_code(t):\n",
    "    return t[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for i in range(len(jobData)):\n",
    "    code.append(extract_country_code(jobData[\"location\"][i]))\n",
    "\n",
    "jobData[\"country_code\"] = code\n",
    "jobData[\"country_code\"] = jobData[\"country_code\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = jobData[\"country_code\"]\n",
    "\n",
    "# generate binary values using get_dummies\n",
    "jobData = pd.get_dummies(jobData, columns=[\"country_code\"], prefix=[\"country_code_is\"], dtype=\"bool\")\n",
    "jobData = jobData.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `telecommuting`, `has_company_logo`, `has_questions` columns dtype to bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData['telecommuting'] = jobData['telecommuting'].astype(bool)\n",
    "jobData['has_company_logo'] = jobData['has_company_logo'].astype(bool)\n",
    "jobData['has_questions'] = jobData['has_questions'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying NLP to generate `NLP_pred`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData = jobData.astype({\n",
    "    'title': 'string',\n",
    "    'department': 'string',   \n",
    "    'company_profile': 'string',\n",
    "    'description': 'string',\n",
    "    'requirements': 'string',\n",
    "    'benefits': 'string',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData['department'].fillna(value='NODEPARTMENT', inplace=True)\n",
    "jobData['company_profile'].fillna(value='NOCOMPANYPROFILE', inplace=True)\n",
    "jobData['description'].fillna(value='NODESCRIPTION', inplace=True)\n",
    "jobData['requirements'].fillna(value='NOREQUIREMENTS', inplace=True)\n",
    "jobData['benefits'].fillna(value='NOBENEFITS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Marketing Intern Marketing We're Food52, and w...\n",
       "1        Customer Service - Cloud Video Production Succ...\n",
       "2        Commissioning Machinery Assistant (CMA) NODEPA...\n",
       "3        Account Executive - Washington DC Sales Our pa...\n",
       "4        Bill Review Manager NODEPARTMENT SpotSource So...\n",
       "                               ...                        \n",
       "17875    Account Director - Distribution  Sales Vend is...\n",
       "17876    Payroll Accountant Accounting WebLinc is the e...\n",
       "17877    Project Cost Control Staff Engineer - Cost Con...\n",
       "17878    Graphic Designer NODEPARTMENT NOCOMPANYPROFILE...\n",
       "17879    Web Application Developers Engineering Vend is...\n",
       "Length: 17880, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = jobData[['title', 'department', 'company_profile', 'description', 'requirements', 'benefits']].agg(' '.join, axis=1)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#Initializes objects needed to perform cleaning\n",
    "regex_token = RegexpTokenizer(r'[a-zA-Z0-9\\-]+')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "#Converts part of speech tag from treebank syntax to wordnet syntax\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    return 'v'\n",
    "\n",
    "#Function to tokenize, filter stop words and lemmatize words in text data\n",
    "def pre_process_lem(text):\n",
    "    \n",
    "    #perform tokenization to obtain a list of words, with each word as an individual element\n",
    "    tokenized_text = regex_token.tokenize(text.lower())\n",
    "    \n",
    "    #Filter out stop words with a loop, adding filtered words to a new list\n",
    "    filtered_tokens=[]\n",
    "    for word in tokenized_text:\n",
    "        if word not in stop_words:\n",
    "            filtered_tokens.append(word)\n",
    "    \n",
    "    #Tags filtered words with their relevant part of speech. Tagging is necessary for lemmatization.\n",
    "    #Returns a tuple (<word>, <tag>), but tag is in treebank syntax.\n",
    "    tagged_words = pos_tag(filtered_tokens)\n",
    "    \n",
    "    #Uses a loop to lemmatize words then add them to a new list\n",
    "    lemmed_words = []\n",
    "    for tagged_word in tagged_words:\n",
    "        #Lemmatizer method takes in (<word>, pos=<tag>) as inputs\n",
    "        #The get_wordnet_pos() method is needed to convert tags from treebank syntax to wordnet syntax.\n",
    "        lemmed_word = lem.lemmatize( tagged_word[0] , pos=get_wordnet_pos(tagged_word[1]) )\n",
    "        lemmed_words.append(lemmed_word)\n",
    "        \n",
    "    return \" \".join(lemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_documents = documents.apply(pre_process_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        marketing intern marketing food52 create groun...\n",
       "1        customer service - cloud video production succ...\n",
       "2        commission machinery assistant cma nodepartmen...\n",
       "3        account executive - washington dc sale passion...\n",
       "4        bill review manager nodepartment spotsource so...\n",
       "                               ...                        \n",
       "17875    account director - distribution sale vend look...\n",
       "17876    payroll accountant accounting weblinc e-commer...\n",
       "17877    project cost control staff engineer - cost con...\n",
       "17878    graphic designer nodepartment nocompanyprofile...\n",
       "17879    web application developer engineering vend loo...\n",
       "Length: 17880, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobData[\"lemmatized_documents\"] = lemmatized_documents\n",
    "lemmatized_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                     int64\n",
       "title                     string\n",
       "location                  object\n",
       "department                string\n",
       "salary_range              string\n",
       "                          ...   \n",
       "country_code_is_VN          bool\n",
       "country_code_is_ZA          bool\n",
       "country_code_is_ZM          bool\n",
       "country_code            category\n",
       "lemmatized_documents      object\n",
       "Length: 310, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobData.to_csv('Datasets/cleaned_data.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
